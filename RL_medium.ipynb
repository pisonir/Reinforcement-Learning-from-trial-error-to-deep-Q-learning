{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPkIcN-_J-w7"
   },
   "source": [
    "# Reinforcement Learning: from trial & error to deep Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_eVXngVMy5v"
   },
   "source": [
    "\n",
    "My objective with this article is to introduce Reinforcement Learning (RL) basics with hands-on examples. I'm going to cover only a few foundational RL concepts needed to understand the practical examples.\n",
    "\n",
    "Although no previous RL knowledge is required, solid Python coding skills and basic machine learning understanding are necessary to follow the content of this article. \n",
    "\n",
    "# The Reinforcement Learning Problem\n",
    "\n",
    "In simple words, RL is a computational approach used to achieve a pre-defined goal, that can be winning a chess game, optimizing a medical treatment or improving a financial trading strategy. RL algorithms are used to answer questions such as:\n",
    "- what is the best apporach to achieve my goal?\n",
    "- Which actions will get me closer to the objective? \n",
    "- How will the system react an action?\n",
    "\n",
    "The goal is to maximize a numerical reward by learning to map situations to actions. This mapping happens through interactions with the environment, i.e. taking actions and observing the consequences of such actions. \n",
    "\n",
    "**Elements of Reinforcement Learning**\n",
    "\n",
    "The following definitions might be confusing at first but they will definitely become clearer once we dive into the practical examples.\n",
    "\n",
    "- *Agent*: it's the system we want to operate, the model we want to build and train with RL. A learning agent has three main characteristics:\n",
    "  *   it has explicit goals,\n",
    "  *   it can sense aspects of its environment,\n",
    "  *  it can choose actions to influence its environment.\n",
    "  \n",
    "\n",
    "- *Environment*: define anything the agent can interact with. \n",
    "- *Action*: an action that the agent takes to interact with the environment. \n",
    "- *State*: it represents the observation of the environment after an action is taken. \n",
    "- *Policy*: it defines the learning agent's way of behaving at a given time. A policy is a function that takes as input the environment's state, at a given time, and returns an action.\n",
    "it can be a simple lookup table, a function or a more extensive search process. In general, policies are stochastic.\n",
    "- *Reward*: it is a signal, a single number. The goal of the learning agent is to increase this number. The reward depends on the current agent's action and environment's state. The learning agent can influence the reward signal in two ways,\n",
    "  - directly through its actions,\n",
    "  - indirectly through changing the environment's state.\n",
    "\n",
    "- *Value*: it is the expected total reward starting from a specific state. While reward defines what is good in the immediate, value defines what is good in the long run. Although, value is secondary, it could not exist without reward, it is the most important component of almost all reinforcement learning algorithms. As a matter of fact, we seek for actions that yield states of highest value, not highest reward. For example a state might yield a low immediate reward but still have a high value because it is regularly followed by other states that yield high rewards, or viceversa. It is much harder to determine values than it is to determine rewards, values must be estimated and re-estimated from the sequences of observations an agent makes over its entire lifetime.\n",
    "- Model of the environment: it mimics the behavior of the environment. Given a state and an action the model predicts the next state and reward. Models of the environemnt are used for planning, deciding a course of actions by considering possible future situations. Methods to solve reinforcement learning problems can be either model-based, model-free (trial and error) or the two combined.\n",
    "\n",
    "**Markov Decision Process**\n",
    "\n",
    "There are few frameworks one can use when working with RL. Here we consider the Markov Decision Process framework.\n",
    "Markov Decision Processes (MDPs) are a formalization of sequential decision processes, where each action affects, not only the immediate reward, but all the subsequent states and therefore future rewards. The MDP framework determines that every goal-oriented decision process can be reduced to only three signals exchanged between agent and environment. These signals are \n",
    "\n",
    "\n",
    "1.   The agent's choices (actions)\n",
    "2.   The basis on which these choices were made (state)\n",
    "3.   The agent's goal (reward)\n",
    "\n",
    "\n",
    "To make our life easier we will only consider *finite* MDPs. In a *finite* MDP the sets of states, actions and rewards have a finite number of elements. \n",
    "The most important characteristic of a MDP is that the reward and new state depend only on the immediately preceding state and action. The preceding state must include all the information of past agent-environment interactions. If it does, then the state is said to have the *Markov property*.\n",
    "\n",
    "A MDP can be visualized with the following diagram. Each timestep, the agent chooses an `action` in a `state`, and the environment returns an `observation` (i.e. a new state) and a `reward`.\n",
    "\n",
    "![learning system loop](imgs/MDP_2x@2x.png)\n",
    "\n",
    "**The exploration - exploitation dilemma**\n",
    "\n",
    "A RL agent needs to find the right balance between exploring the environment, looking for new ways to get rewards, and exploiting the reward sources it has already discovered.\n",
    "\n",
    "To maximize its reward, an agent must prefer actions that it tried in the past and produced reward. In order to discover these actions, the agent must try actions that it has not tried before. It has to *exploit* what it already knows in order to obtain reward, but it also has to *explore* in order to make better choices in the future. Neither exploitation nor exploration can be pursued exclusively without failing at the task. It's a trade off, the agent must balance exploration and exploitation by trying a variety of actions and progressively favor those who appear to produce reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axausc-PoV_A"
   },
   "source": [
    "# The Glass Bridge Challenge\n",
    "\n",
    "We are going to re-create the infamous Glass Bridge challenge from the Netflix series *Squid Game* episode 7.\n",
    "\n",
    "The agent controls the movement of a character in a grid. The character must cross from one side of the bridge to the other - the only catch being that not all the tiles of the bridge are made of tempered glass, some are regular glass that instantly shatters under the weight of the character.\n",
    "\n",
    "![glass bridge challenge](imgs/glass_bridge_2x@2x.png)\n",
    "\n",
    "\n",
    "The agent is rewarded for finding a walkable path to the goal tile (labelled with G), that is the last tile of the bridge made of tempered glass.\n",
    "\n",
    "- The character is the **agent**.\n",
    "- The glass bridge is the **environment**.\n",
    "- Reaching the goal, i.e. crossing the entire bridge without falling, returns a **reward** != 0.\n",
    "- the possible character movements, moving to the next adjacent tile or the opposite one, are the **actions**.\n",
    "- At each action the position of the character changes, the position is the environment's **state**.\n",
    "- A trajectory from start to termination is called an **episode**. The trajectory terminates when the termination condition is met. The termination condition could be achieving the goal, or stepping on a regular glass tile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOTvz6sGuhuC"
   },
   "source": [
    "## OpenAI Gym\n",
    "\n",
    "the OpenAI gym library is a collection of test problems, known as environments, that one can use to work out reinforcement learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AhrlMmiZlMeW"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from io import StringIO\n",
    "from contextlib import closing\n",
    "from tqdm import tqdm\n",
    "from gym import utils\n",
    "from gym.envs.toy_text import discrete\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SID9Cx2lMxFI"
   },
   "source": [
    "## Crossing the glass bridge - trial and error\n",
    "Let's start by understanding the state-action-reward framework.\n",
    "\n",
    "Here I'm adapting the `FrozenLakeEnv` [Github](https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py) defined in the Gym library to re-create the glass bridge from *Squid Game* episode 7 (Netflix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SS0u0BFDuZZe"
   },
   "outputs": [],
   "source": [
    "#@title GlassBridgeEnv\n",
    "RIGHT = 0\n",
    "DIAGONAL = 1\n",
    "\n",
    "MAP = {\n",
    "    \"8x2\": [\"STRRTRTR\",\"RRTTRTRG\"]\n",
    "}\n",
    "\n",
    "class GlassBridgeEnv(discrete.DiscreteEnv):\n",
    "    \"\"\"\n",
    "    Squid Game episode 7: crossing the glass bridge.\n",
    "\n",
    "    --> _|_|_|_|_|_|_|_|\n",
    "        _|_|_|_|_|_|_|_| -->\n",
    "\n",
    "    The surface is described using a grid like the following\n",
    "        STRRTRTRRTRRR \n",
    "        RRTTRTRTTRTTG\n",
    "    S : starting point, safe\n",
    "    T : tempered glass, safe\n",
    "    R : regular glass, fall to your doom\n",
    "    G : goal, where you will be ending your game\n",
    "    The episode ends when you reach the goal or step on a regular glass tile.\n",
    "    You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\", \"ansi\"]}\n",
    "\n",
    "    def __init__(self, desc=None, map_name=\"8x2\", is_slippery=True):\n",
    "        if desc is None and map_name is None:\n",
    "            desc = generate_random_map()\n",
    "        elif desc is None:\n",
    "            desc = MAP[map_name]\n",
    "        self.desc = desc = np.asarray(desc, dtype=\"c\")\n",
    "        self.nrow, self.ncol = nrow, ncol = desc.shape\n",
    "        self.reward_range = (0, 1)\n",
    "\n",
    "        nA = 2 # Number of possible actions.\n",
    "        nS = nrow * ncol # Number of possible states.\n",
    "\n",
    "        # Initial state distribution.\n",
    "        isd = np.array(desc == b\"S\").astype(\"float64\").ravel() \n",
    "        isd /= isd.sum() \n",
    "\n",
    "        P = {s: {a: [] for a in range(nA)} for s in range(nS)} # Transitions.\n",
    "\n",
    "        def to_s(row: int, col: int) -> int:\n",
    "            \"\"\"\n",
    "            to state (row,col).\n",
    "\n",
    "            Returns the new state.\n",
    "            \"\"\"\n",
    "            return row * ncol + col\n",
    "\n",
    "        def inc(row: int, col: int, action: int) -> tuple:\n",
    "            \"\"\"\n",
    "            Increment.\n",
    "\n",
    "            Returns the new (row, col), after an action is taken.\n",
    "            \"\"\"\n",
    "            if action == RIGHT:\n",
    "                col = min(col + 1, ncol - 1)\n",
    "            elif action == DIAGONAL:\n",
    "                col = min(col + 1, ncol - 1)\n",
    "                if row == 0:\n",
    "                    row = 1\n",
    "                elif row == 1:\n",
    "                    row = 0 \n",
    "            return (row, col)\n",
    "\n",
    "        def update_probability_matrix(row: int, col: int, action: int) -> list:\n",
    "            \"\"\"\n",
    "            Returns newstate, reward and a flag indicating whether episode is finished, following action.\n",
    "            \"\"\"\n",
    "            newrow, newcol = inc(row, col, action)\n",
    "            newstate = to_s(newrow, newcol)\n",
    "            newletter = desc[newrow, newcol]\n",
    "            done = bytes(newletter) in b\"GR\"\n",
    "            reward = float(newletter == b\"G\")\n",
    "            return newstate, reward, done\n",
    "\n",
    "        for row in range(nrow):\n",
    "            for col in range(ncol):\n",
    "                s = to_s(row, col)\n",
    "                for a in range(2):\n",
    "                    li = P[s][a]\n",
    "                    letter = desc[row, col]\n",
    "                    if letter in b\"GR\":\n",
    "                        li.append((1.0, s, 0, True)) # (probability, nextstate, reward, done)\n",
    "                    else:\n",
    "                        if is_slippery:\n",
    "                            li.append((0.8, *update_probability_matrix(row, col, a)))\n",
    "                            # Small proabability that the environemnt returns the other action\n",
    "                            li.append((0.2, *update_probability_matrix(row, col, (a+3)%2)))\n",
    "                        else:\n",
    "                            li.append((1.0, *update_probability_matrix(row, col, a)))\n",
    "        print(f\"li: {li}\")\n",
    "        super(GlassBridgeEnv, self).__init__(nS, nA, P, isd) # Calls the parent class discrete.DiscreteEnv\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        outfile = StringIO() if mode == \"ansi\" else sys.stdout\n",
    "\n",
    "        row, col = self.s // self.ncol, self.s % self.ncol\n",
    "        desc = self.desc.tolist()\n",
    "        desc = [[c.decode(\"utf-8\") for c in line] for line in desc]\n",
    "        desc[row][col] = utils.colorize(desc[row][col], \"red\", highlight=True)\n",
    "        if self.lastaction is not None:\n",
    "            outfile.write(\n",
    "                \"  ({})\\n\".format([\"Right\", \"Diagonal\"][self.lastaction])\n",
    "            )\n",
    "        else:\n",
    "            outfile.write(\"\\n\")\n",
    "        outfile.write(\"\\n\".join(\"\".join(line) for line in desc) + \"\\n\")\n",
    "\n",
    "        if mode != \"human\":\n",
    "            with closing(outfile):\n",
    "                return outfile.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvd30QTaUZwZ"
   },
   "source": [
    "Each episode starts by calling `reset()`, which returns an initial `observation` (or environment's state). The actions are randomly sampled (policy) from the environment's action space. The possible actions are:     \n",
    "- RIGHT: move to the adjacent tile on your right (the bridge crosses left to right)\n",
    "- DIAGONAL: move diagonally (i.e. move to the next not adjacent glass tile)\n",
    "\n",
    "In addition, for each action, the environment might return, with a small probability (20%), the result of the alternative action. For example, action `DIAGONAL` might return the agent on the right adjacent glass tile, while `RIGHT` might advance the agent diagonally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1642355380773,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "vcR5uG7THpjh",
    "outputId": "8fca77b2-3093-4cfc-bad2-99419537581b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "li: [(1.0, 15, 0, True)]\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Right)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "Episode finished after 2 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "Episode finished after 1 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "Episode finished after 1 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "Episode finished after 1 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Right)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "Episode finished after 2 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Diagonal)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "Episode finished after 2 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Diagonal)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "Episode finished after 2 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Diagonal)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "Episode finished after 2 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Right)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "Episode finished after 2 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Right)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "  (Diagonal)\n",
      "STRRTRTR\n",
      "RR\u001b[41mT\u001b[0mTRTRG\n",
      "10\n",
      "  (Right)\n",
      "STRRTRTR\n",
      "RRT\u001b[41mT\u001b[0mRTRG\n",
      "11\n",
      "  (Right)\n",
      "STRR\u001b[41mT\u001b[0mRTR\n",
      "RRTTRTRG\n",
      "4\n",
      "Episode finished after 5 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Right)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "  (Diagonal)\n",
      "STRRTRTR\n",
      "RR\u001b[41mT\u001b[0mTRTRG\n",
      "10\n",
      "  (Right)\n",
      "STRRTRTR\n",
      "RRT\u001b[41mT\u001b[0mRTRG\n",
      "11\n",
      "Episode finished after 4 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "Episode finished after 1 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Right)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "Episode finished after 2 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "Episode finished after 1 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Right)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "Episode finished after 2 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "Episode finished after 1 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "Episode finished after 1 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "Episode finished after 1 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Diagonal)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "  (Diagonal)\n",
      "STRRTRTR\n",
      "RR\u001b[41mT\u001b[0mTRTRG\n",
      "10\n",
      "Episode finished after 3 timesteps\n",
      "\n",
      "\u001b[41mS\u001b[0mTRRTRTR\n",
      "RRTTRTRG\n",
      "0\n",
      "  (Right)\n",
      "S\u001b[41mT\u001b[0mRRTRTR\n",
      "RRTTRTRG\n",
      "1\n",
      "  (Right)\n",
      "STRRTRTR\n",
      "RR\u001b[41mT\u001b[0mTRTRG\n",
      "10\n",
      "  (Right)\n",
      "STRRTRTR\n",
      "RRT\u001b[41mT\u001b[0mRTRG\n",
      "11\n",
      "Episode finished after 4 timesteps\n"
     ]
    }
   ],
   "source": [
    "env = GlassBridgeEnv()\n",
    "for i_episode in range(20):\n",
    "    newstate = env.reset()\n",
    "    for t in range(10):\n",
    "        env.render()\n",
    "        print(newstate)\n",
    "        action = env.action_space.sample()\n",
    "        newstate, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RM4YI9i4zgG"
   },
   "source": [
    "The 1st line instantiates a GlassBridge environment.\n",
    "We then loop through 20 episodes.\n",
    "In each episode we reset to the starting glass tile (3rd line).\n",
    "At each time step `t` the agent in a state selects an action, as a result, it receives a numerical reward and finds itself in a new state.\n",
    "In details:\n",
    "\n",
    "The 5th line displays the game.\n",
    "\n",
    "The 7th line prompts an action which is randomly picked.\n",
    "\n",
    "On the 8th line, the action is taken and the environment gives four returns:\n",
    "- `newstate`: an integer representing the position of the agent (see illustration below) after taking `action`.\n",
    "- `reward`: $1$ if `newstate` == goal tile, $0$ otherwise.\n",
    "- `done`: a flag indicating whether the game is over (stepping on regular glass or crossing the bridge safely) or not.\n",
    "- `info`: extra debug information.\n",
    "The 9th line means if the game is done; start a new episode.\n",
    "\n",
    "By recording the agent transitions we can map out the environment. The sequence of these transitions is the agent's *trajectory*.\n",
    "\n",
    "We can directly visualize all the possible trajectories with the following map.\n",
    "\n",
    "![environment map](imgs/env_map2x@2x.png)\n",
    "\n",
    "Recalling MDP, suppose we are in state 6. We know that moving diagonally (action 1) would return a finite reward with high probability. This probability only depends on the current state 6, and not on the previous sequence of states. This is an example of the Markov property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAXcdAq2KhRN"
   },
   "source": [
    "## Q-learning\n",
    "\n",
    "There is always at least one policy that is better than or equal to all other policies. This is called an *optimal policy*.\n",
    "An optimal policy is characterized by an *optimal action-value function*, denoted $q^{*} (s,a)$. For the state-action pair ($s,a$), this function gives the expected return for taking action $a$ in state $s$, following an optimal policy.\n",
    "\n",
    "Let's now introduce an algorithm known as *Q-learning* (Watkins, 1989). The *Q-learning* algorithm allows us to define a *Q* function that directly approximates $q^{*}$.\n",
    "\n",
    "We want to calculate the return, not the immediate reward. At a given time *t*, for a given state-action pair, the **return** is the sum of all rewards until the episode terminates,\n",
    "\n",
    "$$ Q(s_t,a_t) = r_{s_t,a_t} + r_{s_{t+1},a_{t+1}} + \\ldots + r_{s_{t+n-1}, a_{t+n-1}} $$\n",
    "\n",
    "In the above formula, the return, denoted as $Q$, treats equally rewards that will come later with immediate rewards. However, we should take into account that immediate rewards are more desirable and account for delayed future rewards with a discount factor $\\gamma$.\n",
    "\n",
    "$$ Q(s_t,a_t) = r_{s_t,a_t} +  \\gamma r_{s_{t+1},a_{t+1}} + \\gamma^2 r_{s_{t+2},a_{t+2}} + \\ldots + \\gamma^{n-1} r_{s_{t+n-1}, a_{t+n-1}} $$\n",
    "\n",
    "That can be rewritten as\n",
    "$$ Q(s_t,a_t) = r_{s_t,a_t} +  \\gamma Q(s_{t+1},a_{t+1}) $$\n",
    "\n",
    "The agent should choose the action $a_{t+1}$ that maximises return:    \n",
    "$$ Q(s_t,a_t) = r_{s_t,a_t} +  \\gamma \\displaystyle \\max_{\\substack{a_{t+1}}} Q(s_{t+1},a_{t+1}) $$\n",
    "\n",
    "To approximate the optimal action-value function we apply a correction weighted by a learning rate $\\alpha$. By definition, a correction is the difference between the measured action-value function $Q(s_t,a_t)$ and expected action-value function $Q_{expected}(s_t,a_t)$,\n",
    "\n",
    "$$correction =  Q(s_t,a_t) - Q_{expected}(s_t,a_t)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$Q_{updated}(s_t,a_t) \\gets  Q_{expected}(s_t,a_t) + \\alpha \\cdot (Q(s_t,a_t) - Q_{expected}(s_t,a_t))$$\n",
    "\n",
    "which results in\n",
    "\n",
    "$$Q_{updated}(s_t,a_t) \\gets Q_{expected}(s_t,a_t) + \\alpha \\cdot \\left( r_{s_t,a_t} +  \\gamma \\displaystyle \\max_{\\substack{a_{t+1}}} Q(s_{t+1},a_{t+1}) - Q_{expected}(s_t,a_t) \\right)\n",
    "$$\n",
    "\n",
    "The learned action-value function $Q_{updated}(s_t,a_t)$ directly approximates $q^{*}$, the optimal action-value function, independent of the policy being followed. The equation above, to update $Q$, is the famous **Bellman equation**.\n",
    "\n",
    "Let's implement the Bellman equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gBv_OY1UWWml"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "li: [(1.0, 15, 0, True)]\n"
     ]
    }
   ],
   "source": [
    "def bellman_update(Q: np.ndarray, learning_rate: float, discount_factor: float, \n",
    "                   reward: float, state: int, newstate: int, action: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns the updated Q table using the Bellman equation.\n",
    "    \"\"\"\n",
    "    Q[state, action] = Q[state, action] + learning_rate*(\n",
    "                                   reward + \\\n",
    "                                   discount_factor * np.max(Q[newstate,:]) - \\\n",
    "                                   Q[state, action]\n",
    "                                 )\n",
    "    return Q\n",
    "\n",
    "def run_update_rule(env: GlassBridgeEnv(), Q: np.ndarray, learning_rate: float, discount_factor: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Runs the Bellman update with random policy until the episode terminates. \n",
    "    Returns the updated Q table at the end of the episode.\n",
    "    \"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while (not done):\n",
    "        action = env.action_space.sample() # random policy.\n",
    "        newstate, reward, done, _ = env.step(action)\n",
    "        Q = bellman_update(Q, learning_rate, discount_factor, reward, state, newstate, action)\n",
    "        state = newstate\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0LMds7TZlKZ"
   },
   "source": [
    "`Q` is a table that stores Q values.\n",
    "\n",
    "Let's train the agent to solve the `GlassBridgeEnv` by running multiple episodes. At each episode we update the action-value function using the Bellman equation defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u9oZRuK5ZzH6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "li: [(1.0, 15, 0, True)]\n"
     ]
    }
   ],
   "source": [
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "def train_agent(env: GlassBridgeEnv(), episodes: int, learning_rate: float, discount_factor: float) -> np.ndarray:\n",
    "    Q = np.zeros([num_states, num_actions])\n",
    "    for episode in range(episodes):\n",
    "        Q = run_update_rule(env, Q, learning_rate, discount_factor)\n",
    "        print(Q)\n",
    "        clear_output(wait = True)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4395,
     "status": "ok",
     "timestamp": 1642355522602,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "k0ckuyOUbKRA",
    "outputId": "172fca78-894a-4e40-a128-c9e8d213587e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "discount_factor = 0.95   \n",
    "learning_rate = 0.1   \n",
    "episodes = 2000   \n",
    "\n",
    "def normalize_Q(Q: np.ndarray) -> np.ndarray:\n",
    "    Q_max = np.max(Q)\n",
    "    if Q_max > 0.0: # if agent never succeeds, then Q_max = 0\n",
    "        Q = (Q/Q_max)*1\n",
    "    return Q\n",
    "\n",
    "Q = train_agent(env, episodes, learning_rate, discount_factor)\n",
    "print(normalize_Q(Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qbAZU8GnyRh"
   },
   "source": [
    "Note the following characteristics of `Q`:       \n",
    "\n",
    "*   Q-values are normalized in the range [0,1] for readability, where the max value is = 1. This value is actually obtained for the final state-action pair that precedes the goal ($s=6, a=1$).\n",
    "*   Q-values are 0 for the terminal states (the regular glass tiles and the goal state) because no transition occurs from terminal states.\n",
    "*   The higher the Q-value of a state-action pair, the closer that state-action pair is to the goal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl4K8w3Gf0So"
   },
   "source": [
    "Let's now compare our trained agent with an agent choosing random actions. The trained agent will choose the actions with the highest Q-value in order to maximize reward. Such policy is known as **greedy policy**. \n",
    "\n",
    "To compare the two agents we calculate the average reward over a finite number of episodes found either by random or greedy policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1642355533693,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "9g9kExkRcgcQ",
    "outputId": "f72aec4f-0d39-4bf7-ab45-ca67d480a16b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "li: [(1.0, 15, 0, True)]\n",
      "Percentage of successful episodes 20.22022022022022%\n"
     ]
    }
   ],
   "source": [
    "policy = 'greedy'   #@param ['greedy', 'random']\n",
    "episodes = 1000   \n",
    "\n",
    "def run_episode(env: GlassBridgeEnv(), Q: np.ndarray, policy: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns the episode total reward, a.k.a episode's return.\n",
    "    \"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    episode_return = 0\n",
    "    while (not done):\n",
    "        if policy == 'random':\n",
    "            action = env.action_space.sample()\n",
    "        elif policy == 'greedy':\n",
    "            action = np.argmax(Q[state, :])\n",
    "        else:\n",
    "            raise Exception(\"Error: policy must be 'random' or 'greedy'\")\n",
    "        newstate, reward, done, _ = env.step(action)\n",
    "        episode_return += reward\n",
    "        state = newstate\n",
    "    return episode_return \n",
    "\n",
    "total_reward = 0\n",
    "for episodes in range(episodes):\n",
    "    total_reward += run_episode(env, Q, policy)\n",
    "print(f\"Percentage of successful episodes {total_reward/episodes*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNgR4b1FjWDi"
   },
   "source": [
    "The trained agent is superior to the random agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpP6uhNbtMfx"
   },
   "source": [
    "## The exploitation - exploration dilemma\n",
    "\n",
    "Nonetheless, we train the agent for thousands of episodes, the Q-values are still inaccurate. \n",
    "\n",
    "Why is that?!\n",
    "\n",
    "It the beginning, all Q-values are 0, in successive episodes the agent randomly picks an action and by doing this it has a finite probability to find rewarding paths. The caveat is that this random policy doesn't allow the agent to exploit the most rewarding path because it doesn't explore enough paths that could lead to a maximum return.\n",
    "\n",
    "To improve upon random policy, we can use an **epsilon greedy** ($\\epsilon$-greedy) policy instead. This policy works in the following way:     \n",
    "\n",
    "*   At each episode, the agent takes a random action with probability $\\epsilon$ and a greedy action with probability $1-\\epsilon$.\n",
    "*   Over successive episodes the value of $\\epsilon$ decays, switching the policy from random exploration to choosing a path which maximizes reward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "height": 279
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1642355540692,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "rO9Io07hwrnN",
    "outputId": "c7aea8e3-8463-4a6a-fde9-fc703ae4e240"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eps_decay = 0.965\n",
    "episodes = 100\n",
    "\n",
    "epsilon = 1.0\n",
    "eps_values = np.zeros(episodes)\n",
    "\n",
    "for episode in range(episodes):\n",
    "    eps_values[episode] = epsilon\n",
    "    epsilon *= eps_decay\n",
    "\n",
    "# Plot epsilon values\n",
    "plt.scatter(range(episodes),eps_values)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Epsilon');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1uFTJZmVxWEX"
   },
   "outputs": [],
   "source": [
    "def policy_eps_greedy(Q: np.ndarray, state: int, epsilon: float) -> int:\n",
    "    \"\"\"\n",
    "    Returns the action calculated using epsilon greedy policy.\n",
    "    \"\"\"\n",
    "    if np.random.random() < epsilon:\n",
    "        action = env.action_space.sample() # random policy.\n",
    "    else:\n",
    "        action = np.argmax(Q[state,:]) # greedy policy.\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WJolAbhvW7uG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "li: [(1.0, 15, 0, True)]\n"
     ]
    }
   ],
   "source": [
    "def run_epsilon_greedy_episode(env: GlassBridgeEnv(), Q: np.ndarray, epsilon: float, \n",
    "                               learning_rate: float, discount_factor: float) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns tuple containing episode's return and Q table.\n",
    "    \"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    episode_return = 0\n",
    "    while (not done):\n",
    "        action = policy_eps_greedy(Q, state, epsilon)\n",
    "        newstate, reward, done, _ = env.step(action)\n",
    "        episode_return += reward\n",
    "        Q = bellman_update(Q, learning_rate, discount_factor, reward, state, newstate, action)\n",
    "        state = newstate\n",
    "    return (episode_return, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7qkTnaiYte8"
   },
   "source": [
    "## Fine-tuning hyperparameters\n",
    "\n",
    "There are a few guidelines for simple RL problems to boost success.\n",
    "\n",
    "\n",
    "*   The environment is probabilistic and Q-values are randomly initialized, as a result different training runs will return different results. Therefore, do not rely on a single training run to evaluate a set of hyperparameter values. \n",
    "*   The exploitation-exploration dilemma: if the agent is not successful, it might mean that it doesn't explore the environment enough. Keep the `epsilon`value close to 1 to allow the agent to explore for longer.\n",
    "*   If the agent is successful a few times but it doesn't exploit those successes, try the following steps:     \n",
    "    * Adjust the learning rate\n",
    "    * Increase the number of episodes &#8594; train for longer\n",
    "    * Increase the `discount_factor` to ensure that the reward backpropagates sufficiently to the Q-values for the initial states.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "OTxv_s7dbTvV"
   },
   "outputs": [],
   "source": [
    "def train_agent(env: GlassBridgeEnv, epsiodes: int, learning_rate: float, \n",
    "                discount_factor: float, eps_decay: float) -> tuple:\n",
    "    \"\"\"\n",
    "    Trains agent using epsilon greedy policy. Returns array of rewards for each episode and Q table\n",
    "    \"\"\"\n",
    "    reward_history = np.array([])\n",
    "    Q = np.zeros([num_states, num_actions])\n",
    "    epsilon = 1.0\n",
    "    for episode in range(episodes):\n",
    "        reward, Q = run_epsilon_greedy_episode(env, Q, epsilon, learning_rate, discount_factor)\n",
    "        reward_history = np.append(reward_history, reward)\n",
    "        if(epsilon > EPS_MIN):\n",
    "            epsilon *= eps_decay\n",
    "    return (reward_history, Q)\n",
    "\n",
    "def check_success(env: GlassBridgeEnv, Q: np.ndarray):\n",
    "    \"\"\"\n",
    "    Check success rate using learned Q table.\n",
    "    \"\"\"\n",
    "    success = 0\n",
    "    for episode in range(100):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        reward = 0\n",
    "        while not done:\n",
    "            action = np.argmax(Q[state,:])\n",
    "            state, reward, done, _ = env.step(action)\n",
    "        success += reward\n",
    "    print(f\"\\nSuccess rate: {success} %\")\n",
    "    \n",
    "def visualize_training(reward_history: np.array):\n",
    "    \"\"\"\n",
    "    Plots reward and success % over episodes.\n",
    "    \"\"\"\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(range(len(reward_history)), reward_history)\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title('Reward during Training')\n",
    "    num_bins = episodes/1000\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.hist(np.nonzero(reward_history)[0], bins=int(num_bins), range=(0,episodes), rwidth=0.4)\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('# Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "height": 607
    },
    "executionInfo": {
     "elapsed": 1855,
     "status": "ok",
     "timestamp": 1642355678274,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "kBZ2xAGrcN1I",
    "outputId": "9c46e5e8-0214-465a-bd32-86968ba46f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15 0.03]\n",
      " [0.04 0.19]\n",
      " [0.   0.  ]\n",
      " [0.   0.  ]\n",
      " [0.1  0.47]\n",
      " [0.   0.  ]\n",
      " [0.15 0.79]\n",
      " [0.   0.  ]\n",
      " [0.   0.  ]\n",
      " [0.   0.  ]\n",
      " [0.23 0.05]\n",
      " [0.04 0.34]\n",
      " [0.   0.  ]\n",
      " [0.08 0.65]\n",
      " [0.   0.  ]\n",
      " [0.   0.  ]]\n",
      "\n",
      "Success rate: 23.0 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set parameters\n",
    "eps_decay = 0.98 \n",
    "episodes = 20000    \n",
    "discount_factor = 0.95        \n",
    "learning_rate = 0.02       \n",
    "\n",
    "EPS_MIN = 0.05\n",
    "\n",
    "# Run agent, print q-values, and plot reward history.\n",
    "reward_history, Q = train_agent(env, episodes, learning_rate, discount_factor, eps_decay)\n",
    "print(Q)\n",
    "visualize_training(reward_history)\n",
    "check_success(env, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI6vJsPAWAHB"
   },
   "source": [
    "The epsilon-greedy policy successfully balances exploration and exploitation. Combining tabular Q-learning with an epsilon-greedy policy is a powerful approach to solving simple environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJUMGg5rWszy"
   },
   "source": [
    "# Deep Q-Learning\n",
    "\n",
    "Tabular Q-Learning (as discussed in the previous section) builds a table which requires an entry for each state-action combination. If the environment is simple, this is indeed a powerful approach, but if the environment is more complex, with many states and actions, then the Q table's size becomes massive.\n",
    "\n",
    "Instead of using a table we can predict Q values using neural networks.\n",
    "\n",
    "We are going now to implement the same epsilon-greedy policy as above where instead of storing Q-values in a table we use a neural network to generate them.\n",
    "\n",
    "The input to the neural net is the one-hot encoded state, the output is a vector of Q-values for each action. Therefore, the input is a vector of length `num_states` while the output is a vector of length `num_actions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6168,
     "status": "ok",
     "timestamp": 1642355696164,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "ExVA9LSZYyEl",
    "outputId": "d5250cc8-f71b-456f-cb7d-2c7172ae483b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from collections import defaultdict\n",
    "from tqdm import notebook\n",
    "\n",
    "EPSILON_MIN = 0.01 # We will need this for later when we train the agent.\n",
    "\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "num_states, num_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CuESiBThYvQa"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_state(state: int) -> np.array:\n",
    "  \"\"\"\n",
    "  Args:\n",
    "      state: An integer representing the agent's state.\n",
    "  Returns:\n",
    "      A one-hot encoded vector of the input `state`.\n",
    "  \"\"\"\n",
    "  return np.identity(num_states)[state:state+1] # [state:state+1] to expand dimensions, instead of simply [state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QNUO4a_ZQQn"
   },
   "source": [
    "We define a nonlinear neural network with 16 inputs and 2 outputs by using the TF Keras API. \n",
    "The neural net has these characteristics:     \n",
    "* it is made of a single dense layer,\n",
    "* uses `relu` activation function,\n",
    "* weights are initialized with small positive values,\n",
    "* does not use bias. Why?! Given that each neuron corresponds to an action, independently of the state, $Q(s1,a1)$ will have the same bias as $Q(s2,a1)$. Training the model will change this bias and affect multiple predictions at the same time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2860,
     "status": "ok",
     "timestamp": 1642355699276,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "JFRDgkdjeEdi",
    "outputId": "7799f341-5dc8-4b43-c978-b0d8420f1421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def define_model(learning_rate: float):\n",
    "    \"\"\"Returns a shallow neural net defined using tf.keras.\n",
    "    Args:\n",
    "        learning_rate: optimizer learning rate\n",
    "    Returns:\n",
    "        model: A shallow neural net defined using tf.keras input dimension equal to\n",
    "        num_states and output dimension equal to num_actions.\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "                                     keras.layers.Dense(units=num_actions,\n",
    "                                                        input_dim=num_states,\n",
    "                                                        activation='relu',\n",
    "                                                        use_bias=False,\n",
    "                                                        kernel_initializer=keras.initializers.RandomUniform(minval=1e-5, maxval=0.05))\n",
    "                                                        ])\n",
    "    model.compile(optimizer = keras.optimizers.SGD(learning_rate = learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "learning_rate=0.1\n",
    "model = define_model(learning_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcUISQ5Mteqk"
   },
   "source": [
    "How do we train the NN? We follow these steps:      \n",
    "\n",
    "\n",
    "1.   Suppose we are in a state `s0`, the first thing we do is to choose an action for the agent to perform. How do we choose an action? We use, for example, $\\epsilon$-greedy policy. The difference with the Q-tabular learning is that now the neural network replaces the Q-table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tqaqHvbIwdAV"
   },
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BWDdAsjkmMrz"
   },
   "outputs": [],
   "source": [
    "def policy_eps_greedy(env: GlassBridgeEnv, q_values: np.ndarray, epsilon: float) -> int:\n",
    "    \"\"\"Select action given Q-values using epsilon-greedy algorithm.\n",
    "    Args:\n",
    "        q_values: q_values for all possible actions from a state.\n",
    "        epsilon: Current value of epsilon used to select action using epsilon-greedy\n",
    "                 algorithm.\n",
    "    Returns:\n",
    "        action: action to take from the state.\n",
    "    \"\"\"\n",
    "    if(np.random.rand() < epsilon):\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(q_values)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1642355700253,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "EiYqubakwU4j",
    "outputId": "ca61a316-cd4d-4cde-91b7-be8ce88122b1"
   },
   "outputs": [],
   "source": [
    "epsilon = 1.0\n",
    "q_values = model.predict(one_hot_encode_state(state))\n",
    "action = policy_eps_greedy(env, q_values, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ty5ubUxturD1"
   },
   "source": [
    "\n",
    "\n",
    "2.   After taking the action, we record the next state we are in and the reward we got\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "newstate, reward, done, _ = env.step(action)\n",
    "```\n",
    "\n",
    "\n",
    "3.   We then calculate the target Q-value using the Bellman update\n",
    "$Q(s_0, a) = r(s_0, a) + \\gamma \\displaystyle \\max_{\\substack{a_1}} Q(s_1,a_1)$, where $s_0$ is the state of step 1 and $a$ the action we took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-z9JjAbEqlRn"
   },
   "outputs": [],
   "source": [
    "def bellman_update(reward: float, discount_factor: float, model, state_new: int) -> float:\n",
    "    return reward + discount_factor * \\\n",
    "                    np.max(model.predict(one_hot_encode_state(state_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1642355700618,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "iOI7Cg8uys2g",
    "outputId": "9c4b98f4-79eb-40c9-fa49-8f0c7503a94e"
   },
   "outputs": [],
   "source": [
    "q_values[0, action] = bellman_update(reward, discount_factor, model, newstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.02], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUqskIxczKCj"
   },
   "source": [
    "q-values for a state is a 2D array of shape (1,2), e.g. `[[0.04, 0.01]]`, where the two values denote the Q-values of the two possible actions (RIGHT, DIAGONAL), respectively. The `0` value in `q_values[0, action]` is used for `[[0.04, 0.01]]`--> `[0.04, 0.01]`\n",
    "\n",
    "4. Now that we have the target Q-value, we train the NN to predict this Q-value. In this way, next episode, the action we will take in `s_0` will be determined by this new updated Q-value, and ideally the action corresponding to the max q-value will be the one that gets us closer to the final goal.\n",
    "\n",
    "\n",
    "```\n",
    "model.fit(one_hot_encode_state(state), q_values)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jvTjZeaytGn"
   },
   "source": [
    "The four steps above need to be run in a loop. For each episode we return the trained model, the *return* of the episode (or sum of rewards) and the length of the episode. This last metric is very important, because the agent will succeed in performing more and more steps and the episode will last longer as the agent learns. The length of the episode is a great metric to monitor the agent training.\n",
    "\n",
    "The next code snippet is training the agent using Deep Q Network (DQN) and the $\\epsilon$-greedy policy defined above. It records the agent's episode length and the agent's episode reward as metrics and plots them. \n",
    "Generally, one can also define a success threshold (e.g. percentage of successes) to know when stopping training, or as we will do monitor the episode length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "OjjYlzlxtgqY"
   },
   "outputs": [],
   "source": [
    "class TrainAgent:\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "        Initializes training parameters.\n",
    "\n",
    "        Args:\n",
    "              env: environment to train the agent on\n",
    "              model: neural network representing agent used to learn Q-values of\n",
    "                environment\n",
    "              epsilon: starting value of epsilon\n",
    "              discount_factor: factor by which to reduce return from next state when\n",
    "                updating Q-values using Bellman update.\n",
    "              eps_decay: factor to reduce value of epsilon by, on every episode\n",
    "              episodes: number of episodes to train agent for\n",
    "              learning_rate: learning rate used by model\n",
    "        \"\"\"\n",
    "        self.env = params['env']\n",
    "        self.epsilon = params['epsilon']\n",
    "        self.eps_decay = params['eps_decay']\n",
    "        self.discount_factor = params['discount_factor']\n",
    "        self.model = params['model']\n",
    "        self.num_episodes = params['num_episodes']\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Trains the agent by running episodes while checking for successful\n",
    "         learning.\n",
    "        \"\"\"\n",
    "        history = defaultdict(list)\n",
    "        for episode in notebook.tqdm(range(self.num_episodes)):\n",
    "            episode_length, episode_reward = self._train_iter()\n",
    "            history['length_history'].append(episode_length)\n",
    "            history['reward_history'].append(episode_reward)\n",
    "            if self.epsilon > EPSILON_MIN:\n",
    "                self.epsilon *= self.eps_decay\n",
    "            if episode+1 % 500 == 0:\n",
    "                print(f\"\"\"\n",
    "                Episode: {episode},\\n\n",
    "                Avg reward: {np.mean(history['reward_history'][-500:-1])},\\n\n",
    "                Avg Length: {np.mean(history['length_history'][-500:-1])},\\n\n",
    "                Epsilon: {self.epsilon}\n",
    "                \"\"\")\n",
    "        self.visualize_performance(history)\n",
    "        env.close() \n",
    "\n",
    "    def _train_iter(self):\n",
    "        \"\"\"\n",
    "        Runs one episode and trains the model on every state transition.\n",
    "\n",
    "        Runs one episode. On every state transition in the episode, collects the\n",
    "        tuple s, a, r, s'. Then performs Bellman update on Q-values using the tuple\n",
    "        and trains the agent to predict the updated Q-values.\n",
    "\n",
    "        Returns:\n",
    "          episode_length: number of states visited during episode\n",
    "          episode_reward: total reward earned by agent during episode\n",
    "          model: updated model after training during episode\n",
    "        \"\"\"\n",
    "        state = self.env.reset()\n",
    "        episode_reward = 0 \n",
    "        done = False\n",
    "        episode_length = 0\n",
    "        while not done:\n",
    "            episode_length += 1\n",
    "            q_values = self.model.predict(one_hot_encode_state(state))\n",
    "            action = policy_eps_greedy(self.env, q_values, self.epsilon)\n",
    "            newstate, reward, done, _ = self.env.step(action)\n",
    "            q_values[0, action] = bellman_update(reward, self.discount_factor, self.model,\n",
    "                                                newstate)\n",
    "        self.model.fit(one_hot_encode_state(state), q_values, verbose=False)\n",
    "        episode_reward += reward\n",
    "        state = newstate\n",
    "        return episode_length, episode_reward\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_performance(history: dict):\n",
    "        \"\"\"\n",
    "        Plots the reward history and episode length history.\n",
    "\n",
    "        Args:\n",
    "              history: dictionary containing reward history and episode length history\n",
    "        \"\"\"\n",
    "        plt.plot(range(len(history['reward_history'])), history['reward_history'])\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Reward')\n",
    "        plt.title('Reward during training')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(range(len(history['length_history'])), history['length_history'])\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Episode length')\n",
    "        plt.title('Episode length during training')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "-zGG5NRi5C--"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b974c64fdde043898a78ed0d7b524f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    'env':env,\n",
    "    'epsilon': 1.0,\n",
    "    'eps_decay': 0.99,\n",
    "    'discount_factor': 0.95,\n",
    "    'model': define_model(learning_rate=0.1),\n",
    "    'num_episodes': 2000\n",
    "}\n",
    "\n",
    "TrainAgent(params)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFg5UWyk1YyT"
   },
   "source": [
    "The reward from the final state must propagate back to the initial state's Q-values. The higher the `discount_factor`, the greater the fraction of the reward that propagates back. Hence, keep `discount_factor` high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TB9_wzxW3xjA"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output # to clear output on every episode run\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "while(not(done)):\n",
    "    q_values = model.predict(np.identity(num_states)[state:state+1])\n",
    "    action = np.argmax(q_values)\n",
    "    state_new, reward, done,_ = env.step(action)\n",
    "    state = state_new\n",
    "    clear_output()\n",
    "    env.render()\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBFtUYaR-0Kv"
   },
   "source": [
    "## Experience Replay\n",
    "\n",
    "Online DQN is trained on tuples generated during live training, sequentially. This makes the training unstable...why? Because training a model, in sequential order, on a trajectory of states means that successive states are similar. Similar in the sense that these tuples are highly correlated, this goes against the independently and identically distributed (i.i.d.) data rule. Even if we choose our starting state randomly, the remaining actions and states to transition to will be chosen according to the trajectory, they are chosen by the policy over a single step, which does not make the consecutive steps fully independent random samples. To make the sampled observations independent, one should make a new random choice, and to be identically distributed that choice has to be made fairly over the whole dataset.\n",
    "\n",
    "If the model input data is not i.i.d, the model won't be able to generalize well to other data and therefore training becomes unstable.\n",
    "Neural networks rely on the assumption that input data is i.i.d.\n",
    "\n",
    "Enters **Experience Replay**.\n",
    "\n",
    "\n",
    "In online training all the previous tuples are discarded, meaning that the model needs to experience those transitions again and again. Experience replay is the act of sampling a small batch of tuples, which were previously collected in a replay buffer, and using this to train the NN. At every step:\n",
    "\n",
    "*   save the tuple for the state transition to the buffer,\n",
    "*   sample a batch of tuples from the replay buffer and train the NN on it.\n",
    "\n",
    "![experience replay](imgs/exp_replay_2x.png)\n",
    "\n",
    "\n",
    "Training on batches of tuples instead of single tuples makes better use of the agent experience and makes the training more stable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0-bNoSS-0NX"
   },
   "source": [
    "## Target Networks\n",
    "\n",
    "Another method, which complements experience replay, to stabilize DQN training is **Target Networks**. \n",
    "When doing online DQN, at each state transition, the NN weights get updated to improve predictive power. The same weights and network are used to predict the target Q-values. The NN trains using its own predictions. As a result, target Q-values don't remain steady, and we experience the problem of chasing a moving target.\n",
    "\n",
    "To keep target Q-values steady, we compute the target Q-values using a separate neural network called a target network.\n",
    "We would like to update the weight of the target network to increase its predictive power, but we don't want to do that at each transition otherwise we are back at square one. Instead, we update the target network to our main neural network, every $N$ steps. This $N$ can be a hyperparameter to tune.\n",
    "\n",
    "![target networks](imgs/target_2x.png)\n",
    "\n",
    "\n",
    "to build the replay buffer we use the `deque` data structure from Python's `collections` library. It allows us to set a maximum size, and if this size is exceeded it removes the first item and adds the new item at the end of the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "WBqhGigd-0Sl"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class TrainAgent:\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "        Initializes training parameters.\n",
    "\n",
    "        Args:\n",
    "              env: environment to train the agent on\n",
    "              model: neural network representing agent used to learn Q-values of\n",
    "                environment\n",
    "              epsilon: starting value of epsilon\n",
    "              discount_factor: factor by which to reduce return from next state when\n",
    "                updating Q-values using Bellman update.\n",
    "              eps_decay: factor to reduce value of epsilon by, on every episode\n",
    "              episodes: number of episodes to train agent for\n",
    "              learning_rate: learning rate used by model\n",
    "        \"\"\"\n",
    "        self.env = params['env']\n",
    "        self.epsilon = params['epsilon']\n",
    "        self.eps_decay = params['eps_decay']\n",
    "        self.discount_factor = params['discount_factor']\n",
    "        self.model = params['model']\n",
    "        self.target_network = params['target_network']\n",
    "        self.num_episodes = params['num_episodes']\n",
    "        self.replay_buffer_size = params['replay_buffer_size']\n",
    "        self.replay_buffer = deque(maxlen = self.replay_buffer_size)\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.update_target_network_interval = params['update_target_network_interval']\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Trains the agent by running episodes while checking for successful\n",
    "         learning.\n",
    "        \"\"\"\n",
    "        history = defaultdict(list)\n",
    "        for episode in notebook.tqdm(range(self.num_episodes)):\n",
    "            episode_length, episode_reward = self._train_iter()\n",
    "            history['length_history'].append(episode_length)\n",
    "            history['reward_history'].append(episode_reward)\n",
    "            if self.epsilon > EPSILON_MIN:\n",
    "                self.epsilon *= self.eps_decay\n",
    "            if ((episode+1) % self.update_target_network_interval) == 0:\n",
    "                self.target_network.set_weights(self.model.get_weights())\n",
    "            if ((episode+1) % 100) == 0:\n",
    "                print(f\"\"\"\n",
    "                Episode: {episode},\\n\n",
    "                Avg reward: {np.mean(history['reward_history'][-100:-1])},\\n\n",
    "                Avg Length: {np.mean(history['length_history'][-100:-1])},\\n\n",
    "                Epsilon: {self.epsilon}\n",
    "                \"\"\")\n",
    "        self.visualize_performance(history)\n",
    "        env.close() \n",
    "  \n",
    "    def _train_model_w_experience_replay(self):\n",
    "        \"\"\"Samples a batch from the buffer and trains the agent on the batch.\n",
    "\n",
    "        Unpacks feature data from tuples of (state, action, reward, newstate).\n",
    "        Encodes states as one-hot vectors and stacks these vectors into a matrix.\n",
    "        Creates matrix of target Q-values. Uses both matrices to train model in one\n",
    "        call for faster training.\n",
    "\n",
    "        Args:\n",
    "          replay_buffer: deque containing recorded tuples.\n",
    "          batch_size: integer specifying training batch size.\n",
    "          model: neural network representing agent.\n",
    "          discount_factor: factor by which to reduce return from next state when\n",
    "            updating Q-values using Bellman update.\n",
    "        Returns:\n",
    "          model: neural network trained on sampled batch.\n",
    "        \"\"\"\n",
    "        if(len(self.replay_buffer) > self.batch_size):\n",
    "            batch = random.sample(self.replay_buffer, self.batch_size)\n",
    "            states, actions, rewards, newstates = [list(tup) for tup in zip(*batch)]\n",
    "            one_hot_encoded_states = np.empty(shape=(0,num_states))\n",
    "            for state in states:\n",
    "                one_hot_encoded_states = np.vstack((one_hot_encoded_states, one_hot_encode_state(state)))\n",
    "            target_q_values = self.target_network.predict(one_hot_encoded_states)\n",
    "            for i in range(len(states)):\n",
    "                target_q_values[i, actions[i]] = bellman_update(rewards[i], \n",
    "                                                                self.discount_factor, \n",
    "                                                                self.target_network, \n",
    "                                                                newstates[i])\n",
    "            self.model.fit(one_hot_encoded_states, target_q_values, verbose = False)\n",
    "      \n",
    "\n",
    "    def _train_iter(self):\n",
    "        \"\"\"\n",
    "        Runs one episode and trains the model on every state transition.\n",
    "\n",
    "        Runs one episode. On every state transition in the episode, collects the\n",
    "        tuple s, a, r, s'. Then performs Bellman update on Q-values using the tuple\n",
    "        and trains the agent to predict the updated Q-values.\n",
    "\n",
    "        Returns:\n",
    "          episode_length: number of states visited during episode\n",
    "          episode_reward: total reward earned by agent during episode\n",
    "          model: updated model after training during episode\n",
    "        \"\"\"\n",
    "        state = self.env.reset()\n",
    "        episode_reward = 0 \n",
    "        done = False\n",
    "        episode_length = 0\n",
    "        while not done:\n",
    "            episode_length += 1\n",
    "            q_values = self.model.predict(one_hot_encode_state(state))\n",
    "            action = policy_eps_greedy(self.env, q_values, self.epsilon)\n",
    "            newstate, reward, done, _ = self.env.step(action)\n",
    "            self.replay_buffer.append((state, action, reward, newstate))\n",
    "            self._train_model_w_experience_replay()\n",
    "            episode_reward += reward\n",
    "            state = newstate\n",
    "        return episode_length, episode_reward\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_performance(history: dict):\n",
    "        \"\"\"\n",
    "        Plots the reward history and episode length history.\n",
    "\n",
    "        Args:\n",
    "              history: dictionary containing reward history and episode length history\n",
    "        \"\"\"\n",
    "        plt.plot(range(len(history['reward_history'])), history['reward_history'])\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Reward')\n",
    "        plt.title('Reward during training')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(range(len(history['length_history'])), history['length_history'])\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Episode length')\n",
    "        plt.title('Episode length during training')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "height": 1000,
     "referenced_widgets": [
      "8d03cbe18f4d42d4b691e40685c4778d",
      "a4d590f7c6284bf9984a6a79b48a2023",
      "46cb9c0b773a493f91d7ad82994fdd4a",
      "c153de30f42f4f509955a22e6726a179",
      "fe41c112577b40c090792d6dbceda2bd",
      "b696d9598ce74f9ab441748fb05b0986",
      "34e2486eb5414ebe99c0a02fd13fae98",
      "a43eeb4fab2f4574a675799c20580b38",
      "3e4eeddcb954424e94792b45d9ed2516",
      "a2cf27f2ddc94d33880c9a1a9039d481",
      "2c8be598d4974c598238a7cff27614d9"
     ]
    },
    "executionInfo": {
     "elapsed": 1714665,
     "status": "ok",
     "timestamp": 1639466289173,
     "user": {
      "displayName": "Riccardo Pisoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIGKGMiSf8BzgUVsZnBRnoZbPC-FSvEzoPyfF_=s64",
      "userId": "15979285378475721637"
     },
     "user_tz": -60
    },
    "id": "e3kShWHuwqL4",
    "outputId": "6390f32d-ebc0-46a5-d2b7-7e62367170c1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93659399b4b8476c8cbda0033b4461e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Episode: 99,\n",
      "\n",
      "                Avg reward: 0.0,\n",
      "\n",
      "                Avg Length: 2.01010101010101,\n",
      "\n",
      "                Epsilon: 0.9047921471137096\n",
      "                \n",
      "\n",
      "                Episode: 199,\n",
      "\n",
      "                Avg reward: 0.0,\n",
      "\n",
      "                Avg Length: 2.0707070707070705,\n",
      "\n",
      "                Epsilon: 0.818648829478636\n",
      "                \n",
      "\n",
      "                Episode: 299,\n",
      "\n",
      "                Avg reward: 0.0,\n",
      "\n",
      "                Avg Length: 2.090909090909091,\n",
      "\n",
      "                Epsilon: 0.7407070321560997\n",
      "                \n",
      "\n",
      "                Episode: 399,\n",
      "\n",
      "                Avg reward: 0.020202020202020204,\n",
      "\n",
      "                Avg Length: 2.0,\n",
      "\n",
      "                Epsilon: 0.6701859060067403\n",
      "                \n",
      "\n",
      "                Episode: 499,\n",
      "\n",
      "                Avg reward: 0.0,\n",
      "\n",
      "                Avg Length: 2.1616161616161618,\n",
      "\n",
      "                Epsilon: 0.6063789448611848\n",
      "                \n",
      "\n",
      "                Episode: 599,\n",
      "\n",
      "                Avg reward: 0.020202020202020204,\n",
      "\n",
      "                Avg Length: 2.4646464646464645,\n",
      "\n",
      "                Epsilon: 0.5486469074854965\n",
      "                \n",
      "\n",
      "                Episode: 699,\n",
      "\n",
      "                Avg reward: 0.0,\n",
      "\n",
      "                Avg Length: 2.282828282828283,\n",
      "\n",
      "                Epsilon: 0.4964114134310989\n",
      "                \n",
      "\n",
      "                Episode: 799,\n",
      "\n",
      "                Avg reward: 0.0,\n",
      "\n",
      "                Avg Length: 2.3636363636363638,\n",
      "\n",
      "                Epsilon: 0.4491491486100748\n",
      "                \n",
      "\n",
      "                Episode: 899,\n",
      "\n",
      "                Avg reward: 0.010101010101010102,\n",
      "\n",
      "                Avg Length: 2.121212121212121,\n",
      "\n",
      "                Epsilon: 0.4063866225452039\n",
      "                \n",
      "\n",
      "                Episode: 999,\n",
      "\n",
      "                Avg reward: 0.020202020202020204,\n",
      "\n",
      "                Avg Length: 2.282828282828283,\n",
      "\n",
      "                Epsilon: 0.3676954247709635\n",
      "                \n",
      "\n",
      "                Episode: 1099,\n",
      "\n",
      "                Avg reward: 0.1111111111111111,\n",
      "\n",
      "                Avg Length: 2.797979797979798,\n",
      "\n",
      "                Epsilon: 0.33268793286240766\n",
      "                \n",
      "\n",
      "                Episode: 1199,\n",
      "\n",
      "                Avg reward: 0.13131313131313133,\n",
      "\n",
      "                Avg Length: 3.01010101010101,\n",
      "\n",
      "                Epsilon: 0.3010134290933992\n",
      "                \n",
      "\n",
      "                Episode: 1299,\n",
      "\n",
      "                Avg reward: 0.08080808080808081,\n",
      "\n",
      "                Avg Length: 3.2222222222222223,\n",
      "\n",
      "                Epsilon: 0.27235458681947705\n",
      "                \n",
      "\n",
      "                Episode: 1399,\n",
      "\n",
      "                Avg reward: 0.06060606060606061,\n",
      "\n",
      "                Avg Length: 2.8282828282828283,\n",
      "\n",
      "                Epsilon: 0.24642429138466176\n",
      "                \n",
      "\n",
      "                Episode: 1499,\n",
      "\n",
      "                Avg reward: 0.1111111111111111,\n",
      "\n",
      "                Avg Length: 3.505050505050505,\n",
      "\n",
      "                Epsilon: 0.22296276370290227\n",
      "                \n",
      "\n",
      "                Episode: 1599,\n",
      "\n",
      "                Avg reward: 0.15151515151515152,\n",
      "\n",
      "                Avg Length: 3.3434343434343434,\n",
      "\n",
      "                Epsilon: 0.20173495769715546\n",
      "                \n",
      "\n",
      "                Episode: 1699,\n",
      "\n",
      "                Avg reward: 0.12121212121212122,\n",
      "\n",
      "                Avg Length: 3.242424242424242,\n",
      "\n",
      "                Epsilon: 0.18252820552270246\n",
      "                \n",
      "\n",
      "                Episode: 1799,\n",
      "\n",
      "                Avg reward: 0.13131313131313133,\n",
      "\n",
      "                Avg Length: 3.515151515151515,\n",
      "\n",
      "                Epsilon: 0.1651500869836984\n",
      "                \n",
      "\n",
      "                Episode: 1899,\n",
      "\n",
      "                Avg reward: 0.15151515151515152,\n",
      "\n",
      "                Avg Length: 3.8484848484848486,\n",
      "\n",
      "                Epsilon: 0.14942650179799613\n",
      "                \n",
      "\n",
      "                Episode: 1999,\n",
      "\n",
      "                Avg reward: 0.1414141414141414,\n",
      "\n",
      "                Avg Length: 3.3535353535353534,\n",
      "\n",
      "                Epsilon: 0.1351999253974994\n",
      "                \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    'env':env,\n",
    "    'epsilon': 1.0,\n",
    "    'eps_decay': 0.999,\n",
    "    'discount_factor': 0.98,\n",
    "    'model': define_model(learning_rate=0.1),\n",
    "    'target_network': define_model(learning_rate=0.1),\n",
    "    'num_episodes': 2000,\n",
    "    'replay_buffer_size': 2000,\n",
    "    'batch_size':8,\n",
    "    'update_target_network_interval': 10\n",
    "}\n",
    "\n",
    "TrainAgent(params)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd_vRagj593F"
   },
   "source": [
    "# References\n",
    "\n",
    "*   R. Sutton and A. Barto, *Reinforcement Learning: An Introduction*, 2nd edition(2018), The MIT Press\n",
    "*   https://github.com/openai/gym\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "RL_medium.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2c8be598d4974c598238a7cff27614d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34e2486eb5414ebe99c0a02fd13fae98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e4eeddcb954424e94792b45d9ed2516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46cb9c0b773a493f91d7ad82994fdd4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a43eeb4fab2f4574a675799c20580b38",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e4eeddcb954424e94792b45d9ed2516",
      "value": 2000
     }
    },
    "8d03cbe18f4d42d4b691e40685c4778d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4d590f7c6284bf9984a6a79b48a2023",
       "IPY_MODEL_46cb9c0b773a493f91d7ad82994fdd4a",
       "IPY_MODEL_c153de30f42f4f509955a22e6726a179"
      ],
      "layout": "IPY_MODEL_fe41c112577b40c090792d6dbceda2bd"
     }
    },
    "a2cf27f2ddc94d33880c9a1a9039d481": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a43eeb4fab2f4574a675799c20580b38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4d590f7c6284bf9984a6a79b48a2023": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b696d9598ce74f9ab441748fb05b0986",
      "placeholder": "​",
      "style": "IPY_MODEL_34e2486eb5414ebe99c0a02fd13fae98",
      "value": "100%"
     }
    },
    "b696d9598ce74f9ab441748fb05b0986": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c153de30f42f4f509955a22e6726a179": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2cf27f2ddc94d33880c9a1a9039d481",
      "placeholder": "​",
      "style": "IPY_MODEL_2c8be598d4974c598238a7cff27614d9",
      "value": " 2000/2000 [28:34&lt;00:00,  1.49it/s]"
     }
    },
    "fe41c112577b40c090792d6dbceda2bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
